{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de021f8a-d64d-48aa-b2d5-27385e954df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dtype_dict = {\n",
    "    \"OrdCat\": \"object\",  #Set columns as object\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"data/Insurance_claim_train.csv\", dtype=dtype_dict, low_memory=False)\n",
    "\n",
    "# Replace '?' with NaN for proper missing value handling\n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b34549d-aebb-46a8-b877-aae3ba8248ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 35 columns):\n",
      " #   Column          Non-Null Count    Dtype  \n",
      "---  ------          --------------    -----  \n",
      " 0   Row_ID          1000000 non-null  int64  \n",
      " 1   Household_ID    1000000 non-null  int64  \n",
      " 2   Vehicle         1000000 non-null  int64  \n",
      " 3   Calendar_Year   1000000 non-null  int64  \n",
      " 4   Model_Year      1000000 non-null  int64  \n",
      " 5   Blind_Make      999609 non-null   object \n",
      " 6   Blind_Model     999609 non-null   object \n",
      " 7   Blind_Submodel  999609 non-null   object \n",
      " 8   Cat1            997475 non-null   object \n",
      " 9   Cat2            615951 non-null   object \n",
      " 10  Cat3            999664 non-null   object \n",
      " 11  Cat4            556566 non-null   object \n",
      " 12  Cat5            556202 non-null   object \n",
      " 13  Cat6            997475 non-null   object \n",
      " 14  Cat7            429802 non-null   object \n",
      " 15  Cat8            999785 non-null   object \n",
      " 16  Cat9            1000000 non-null  object \n",
      " 17  Cat10           999700 non-null   object \n",
      " 18  Cat11           997610 non-null   object \n",
      " 19  Cat12           997798 non-null   object \n",
      " 20  OrdCat          999444 non-null   object \n",
      " 21  Var1            1000000 non-null  float64\n",
      " 22  Var2            1000000 non-null  float64\n",
      " 23  Var3            1000000 non-null  float64\n",
      " 24  Var4            1000000 non-null  float64\n",
      " 25  Var5            1000000 non-null  float64\n",
      " 26  Var6            1000000 non-null  float64\n",
      " 27  Var7            1000000 non-null  float64\n",
      " 28  Var8            1000000 non-null  float64\n",
      " 29  NVCat           1000000 non-null  object \n",
      " 30  NVVar1          1000000 non-null  float64\n",
      " 31  NVVar2          1000000 non-null  float64\n",
      " 32  NVVar3          1000000 non-null  float64\n",
      " 33  NVVar4          1000000 non-null  float64\n",
      " 34  Claim_Amount    1000000 non-null  float64\n",
      "dtypes: float64(13), int64(5), object(17)\n",
      "memory usage: 267.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Print info \n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a92dffc-3f6e-4a6d-802d-6897424edadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns Row_ID and Household_ID\n",
    "df.drop(columns=[\"Row_ID\", \"Household_ID\"], inplace=True)\n",
    "\n",
    "df[\"Claim_Binary\"] = (df[\"Claim_Amount\"] > 0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82472b1-4084-4d7b-8534-f09b9bd3ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 34 columns):\n",
      " #   Column          Non-Null Count    Dtype   \n",
      "---  ------          --------------    -----   \n",
      " 0   Vehicle         1000000 non-null  int64   \n",
      " 1   Calendar_Year   1000000 non-null  int64   \n",
      " 2   Model_Year      1000000 non-null  int64   \n",
      " 3   Blind_Make      999609 non-null   category\n",
      " 4   Blind_Model     999609 non-null   category\n",
      " 5   Blind_Submodel  999609 non-null   category\n",
      " 6   Cat1            997475 non-null   category\n",
      " 7   Cat2            615951 non-null   category\n",
      " 8   Cat3            999664 non-null   category\n",
      " 9   Cat4            556566 non-null   category\n",
      " 10  Cat5            556202 non-null   category\n",
      " 11  Cat6            997475 non-null   category\n",
      " 12  Cat7            429802 non-null   category\n",
      " 13  Cat8            999785 non-null   category\n",
      " 14  Cat9            1000000 non-null  category\n",
      " 15  Cat10           999700 non-null   category\n",
      " 16  Cat11           997610 non-null   category\n",
      " 17  Cat12           997798 non-null   category\n",
      " 18  OrdCat          999444 non-null   category\n",
      " 19  Var1            1000000 non-null  float64 \n",
      " 20  Var2            1000000 non-null  float64 \n",
      " 21  Var3            1000000 non-null  float64 \n",
      " 22  Var4            1000000 non-null  float64 \n",
      " 23  Var5            1000000 non-null  float64 \n",
      " 24  Var6            1000000 non-null  float64 \n",
      " 25  Var7            1000000 non-null  float64 \n",
      " 26  Var8            1000000 non-null  float64 \n",
      " 27  NVCat           1000000 non-null  category\n",
      " 28  NVVar1          1000000 non-null  float64 \n",
      " 29  NVVar2          1000000 non-null  float64 \n",
      " 30  NVVar3          1000000 non-null  float64 \n",
      " 31  NVVar4          1000000 non-null  float64 \n",
      " 32  Claim_Amount    1000000 non-null  float64 \n",
      " 33  Claim_Binary    1000000 non-null  int64   \n",
      "dtypes: category(17), float64(13), int64(4)\n",
      "memory usage: 147.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\n",
    "    'Blind_Make','Blind_Model','Blind_Submodel',\n",
    "    'Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5', 'Cat6', 'Cat7', 'Cat8', \n",
    "    'Cat9', 'Cat10', 'Cat11', 'Cat12', 'NVCat', 'OrdCat'  # Exclude high-cardinality ones like Blind_Make\n",
    "]\n",
    "\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c82bd87-de7a-46cf-8a47-12931766035d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Blind_Make', 'Blind_Model', 'Blind_Submodel', 'Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5', 'Cat6', 'Cat7', 'Cat8', 'Cat9', 'Cat10', 'Cat11', 'Cat12', 'OrdCat', 'NVCat']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['category']).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5a16def-24b8-4f58-8eac-b52065dff39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: (1000000, 3767)\n",
      "Memory usage: 0.21 GB\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode ONLY categorical columns\n",
    "df_encoded = pd.get_dummies(\n",
    "    df,\n",
    "    columns=categorical_columns,\n",
    "    sparse=True,  # Use sparse data structure\n",
    "    dtype='uint8'  # Reduce memory to 1 byte per value\n",
    ")\n",
    "\n",
    "print(f\"Encoded shape: {df_encoded.shape}\")\n",
    "print(f\"Memory usage: {df_encoded.memory_usage(deep=True).sum() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316256e-743e-454e-87c2-5ba25e165212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is already loaded and preprocessed\n",
    "X = df_encoded.drop(columns=[\"Claim_Amount\", \"Claim_Binary\"])  # Features\n",
    "y = df_encoded[\"Claim_Binary\"]  # Target\n",
    "\n",
    "# Split the dataset into training and test sets (stratify ensures class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2824d0-6936-4a63-b8ed-9f38fee36268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "# Define LightGBM Parameters\n",
    "params_with_efb = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbose': 1,\n",
    "    'data_sample_strategy': 'goss',\n",
    "}\n",
    "\n",
    "# Create LightGBM Datasets\n",
    "train_data_with_efb = lgb.Dataset(X_train, y_train,  params={'enable_bundle': True})\n",
    "valid_data_with_efb = lgb.Dataset(X_test, y_test, params={'enable_bundle': True})\n",
    "\n",
    "print(\"Training LightGBM Model with EFB Enabled...\")\n",
    "start_time_with_efb = time.time()\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evals_result_with_efb = {}\n",
    "\n",
    "# Train the model with EFB\n",
    "model_with_efb = lgb.train(\n",
    "    params_with_efb,\n",
    "    train_data_with_efb,\n",
    "    valid_sets=[valid_data_with_efb],\n",
    "    valid_names=['validation'],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result_with_efb),\n",
    "        lgb.early_stopping(stopping_rounds=10, verbose=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_time_with_efb = time.time() - start_time_with_efb\n",
    "best_iter_with_efb = model_with_efb.best_iteration\n",
    "\n",
    "print(f\"\\nLightGBM Model with EFB Enabled Training Complete. Best Iteration: {best_iter_with_efb}\")\n",
    "print(f\"Training Time: {training_time_with_efb:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839afa3-6af5-46d0-bb0a-1f51925ca061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LightGBM Parameters (EFB Disabled)\n",
    "params_without_efb = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'verbose': 1,\n",
    "}\n",
    "\n",
    "# Create LightGBM Datasets\n",
    "train_data_without_efb = lgb.Dataset(X_train, y_train, params={'enable_bundle': False, 'use_missing':True})\n",
    "valid_data_without_efb = lgb.Dataset(X_test, y_test, params={'enable_bundle': False,'use_missing':True})\n",
    "\n",
    "print(\"Training LightGBM Model with EFB Disabled...\")\n",
    "start_time_without_efb = time.time()\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evals_result_without_efb = {}\n",
    "\n",
    "# Train the model without EFB\n",
    "model_without_efb = lgb.train(\n",
    "    params_without_efb,\n",
    "    train_data_without_efb,\n",
    "    valid_sets=[valid_data_without_efb],\n",
    "    valid_names=['validation'],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result_without_efb),\n",
    "        lgb.early_stopping(stopping_rounds=10, verbose=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_time_without_efb = time.time() - start_time_without_efb\n",
    "best_iter_without_efb = model_without_efb.best_iteration\n",
    "\n",
    "print(f\"\\nLightGBM Model with EFB Disabled Training Complete. Best Iteration: {best_iter_without_efb}\")\n",
    "print(f\"Training Time: {training_time_without_efb:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93faf303-70ee-42d6-908a-67d57659103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract AUC values from evaluation results\n",
    "auc_with_efb = np.array(evals_result_with_efb['validation']['auc'])\n",
    "auc_without_efb = np.array(evals_result_without_efb['validation']['auc'])\n",
    "\n",
    "# Generate time per iteration assuming uniform distribution of total time\n",
    "time_per_iter_with_efb = np.linspace(0, training_time_with_efb, len(auc_with_efb))\n",
    "time_per_iter_without_efb = np.linspace(0, training_time_without_efb, len(auc_without_efb))\n",
    "\n",
    "# Plot AUC vs. Training Time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_per_iter_with_efb, auc_with_efb, label='EFB Enabled', linestyle='-')\n",
    "plt.plot(time_per_iter_without_efb, auc_without_efb, label='EFB Disabled', linestyle='--')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"Training Time (seconds)\")\n",
    "plt.ylabel(\"Validation AUC\")\n",
    "plt.title(\"AUC Over Training Time (EFB Enabled vs. Disabled)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d0153-fcc2-4770-8406-e8ffde933d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import time  # ensure you have imported time\n",
    "\n",
    "# For histogram splitting\n",
    "params_xgb_hist = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'verbosity': 1,\n",
    "    'tree_method': 'hist'  # Use histogram-based splitting\n",
    "}\n",
    "\n",
    "\n",
    "# Create XGBoost DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "print(\"Training XGBoost Model Histogram...\")\n",
    "start_time_xgb = time.time()\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evals_result_xgb_hist = {}\n",
    "\n",
    "# Train the model\n",
    "model_xgb = xgb.train(\n",
    "    params_xgb_hist,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dvalid, 'validation')],\n",
    "    early_stopping_rounds=10,\n",
    "    evals_result=evals_result_xgb_hist,\n",
    "    verbose_eval=True\n",
    ")\n",
    "\n",
    "training_time_xgb = time.time() - start_time_xgb\n",
    "best_iter_xgb = model_xgb.best_iteration\n",
    "\n",
    "print(f\"\\nXGBoost Model Training Complete. Best Iteration: {best_iter_xgb}\")\n",
    "print(f\"Training Time: {training_time_xgb:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81b21f6-aec8-48dc-ad94-b723997e9e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, for exact splitting\n",
    "params_xgb_exact = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'verbosity': 1,\n",
    "    'tree_method': 'exact'  # Use exact splitting\n",
    "}\n",
    "\n",
    "print(\"Training XGBoost Model Exact...\")\n",
    "start_time_xgb_exact = time.time()\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evals_result_xgb_exact = {}\n",
    "\n",
    "# Train the model\n",
    "model_xgb_exact = xgb.train(\n",
    "    params_xgb_exact,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    evals=[(dvalid, 'validation')],\n",
    "    early_stopping_rounds=10,\n",
    "    evals_result=evals_result_xgb_exact,\n",
    "    verbose_eval=True\n",
    ")\n",
    "\n",
    "training_time_xgb_exact = time.time() - start_time_xgb_exact\n",
    "best_iter_xgb_exact = model_xgb_exact.best_iteration\n",
    "\n",
    "print(f\"\\nXGBoost Model Training Complete. Best Iteration: {best_iter_xgb_exact}\")\n",
    "print(f\"Training Time: {training_time_xgb_exact:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e9ba0-4fec-4f02-a62b-9f0436f9e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- XGBoost Histogram Splitting ---\n",
    "# Extract AUC values and generate time stamps for histogram splitting model\n",
    "auc_hist = np.array(evals_result_xgb_hist['validation']['auc'])\n",
    "time_per_iter_hist = np.linspace(0, training_time_xgb, len(auc_hist))\n",
    "\n",
    "# --- XGBoost Exact Splitting ---\n",
    "# Extract AUC values and generate time stamps for exact splitting model\n",
    "auc_exact = np.array(evals_result_xgb_exact['validation']['auc'])\n",
    "time_per_iter_exact = np.linspace(0, training_time_xgb_exact, len(auc_exact))\n",
    "\n",
    "# --- Combined Plot ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_per_iter_hist, auc_hist, label='XGBoost Histogram Splitting', color='blue', linestyle='-')\n",
    "plt.plot(time_per_iter_exact, auc_exact, label='XGBoost Exact Splitting', color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Training Time (seconds)\")\n",
    "plt.ylabel(\"Validation AUC\")\n",
    "plt.title(\"XGBoost Splitting Methods Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ca7fa-d576-4dbf-b79b-763070d0ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- LightGBM Models ---\n",
    "# Extract AUC values and generate time stamps for LightGBM (EFB Enabled and Disabled)\n",
    "auc_with_efb = np.array(evals_result_with_efb['validation']['auc'])\n",
    "auc_without_efb = np.array(evals_result_without_efb['validation']['auc'])\n",
    "time_per_iter_with_efb = np.linspace(0, training_time_with_efb, len(auc_with_efb))\n",
    "time_per_iter_without_efb = np.linspace(0, training_time_without_efb, len(auc_without_efb))\n",
    "\n",
    "# --- XGBoost Models ---\n",
    "# (Using the same variables from Cell 1)\n",
    "auc_hist = np.array(evals_result_xgb_hist['validation']['auc'])\n",
    "time_per_iter_hist = np.linspace(0, training_time_xgb, len(auc_hist))\n",
    "\n",
    "auc_exact = np.array(evals_result_xgb_exact['validation']['auc'])\n",
    "time_per_iter_exact = np.linspace(0, training_time_xgb_exact, len(auc_exact))\n",
    "\n",
    "# --- Combined Plot ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot LightGBM models\n",
    "plt.plot(time_per_iter_with_efb, auc_with_efb, label='LightGBM EFB Enabled', color='green', linestyle='-')\n",
    "plt.plot(time_per_iter_without_efb, auc_without_efb, label='LightGBM EFB Disabled', color='orange', linestyle='--')\n",
    "\n",
    "# Plot XGBoost models\n",
    "plt.plot(time_per_iter_hist, auc_hist, label='XGBoost Histogram Splitting', color='blue', linestyle='-')\n",
    "plt.plot(time_per_iter_exact, auc_exact, label='XGBoost Exact Splitting', color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Training Time (seconds)\")\n",
    "plt.ylabel(\"Validation AUC\")\n",
    "plt.title(\"LightGBM vs. XGBoost Model Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e607e24-9a5a-4f5b-8d6a-71fc7b15f5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IR Project)",
   "language": "python",
   "name": "venv_ir_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
