{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de021f8a-d64d-48aa-b2d5-27385e954df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dtype_dict = {\n",
    "    \"OrdCat\": \"object\",  # Explicitly set this column as categorical\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"data/Insurance_claim_train.csv\", dtype=dtype_dict, low_memory=False)\n",
    "\n",
    "# Replace '?' with NaN for proper missing value handling\n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34549d-aebb-46a8-b877-aae3ba8248ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print info \n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a92dffc-3f6e-4a6d-802d-6897424edadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns Row_ID and Household_ID\n",
    "df.drop(columns=[\"Row_ID\"], inplace=True)\n",
    "\n",
    "df[\"Claim_Binary\"] = (df[\"Claim_Amount\"] > 0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82472b1-4084-4d7b-8534-f09b9bd3ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'Blind_Make','Blind_Model','Blind_Submodel',\n",
    "    'Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5', 'Cat6', 'Cat7', 'Cat8', \n",
    "    'Cat9', 'Cat10', 'Cat11', 'Cat12', 'NVCat', 'OrdCat'  # Exclude high-cardinality ones like Blind_Make\n",
    "]\n",
    "\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316256e-743e-454e-87c2-5ba25e165212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X = df.drop(columns=[\"Claim_Amount\", \"Claim_Binary\"])  # Features\n",
    "y = df[\"Claim_Binary\"]  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0642d6-df3f-46e0-86ff-285bdc9d166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set parameters for both models\n",
    "params_baseline = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'enable_bundle': False,        \n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,  # Set high, will stop early if needed\n",
    "    'subsample': 1.0,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "params_efb_goss = {\n",
    "    'boosting_type': 'goss',       \n",
    "    'enable_bundle': True,         \n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,  \n",
    "    'subsample': 1.0,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Create models\n",
    "model_baseline = lgb.LGBMClassifier(**params_baseline)\n",
    "model_efb_goss = lgb.LGBMClassifier(**params_efb_goss)\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evals_result_baseline = {}\n",
    "evals_result_efb_goss = {}\n",
    "\n",
    "# Track training time per iteration\n",
    "time_per_iter_baseline = []\n",
    "time_per_iter_efb_goss = []\n",
    "\n",
    "# Callback function to track time per iteration and print the current estimator\n",
    "def tracking_callback(time_list, model_name):\n",
    "    def callback(env):\n",
    "        current_iter = env.iteration  # Get current boosting round\n",
    "        time_list.append(time.time())\n",
    "        print(f\"{model_name}: Iteration {current_iter}/{env.end_iteration}\", end='\\r', flush=True)\n",
    "    return callback\n",
    "\n",
    "# Train baseline model with tracking\n",
    "print(\"Training baseline model...\")\n",
    "start_time_baseline = time.time()\n",
    "model_baseline.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result_baseline),\n",
    "        lgb.early_stopping(stopping_rounds=10, verbose=True),\n",
    "        tracking_callback(time_per_iter_baseline, \"Baseline Model\")\n",
    "    ]\n",
    ")\n",
    "training_time_baseline = time.time() - start_time_baseline\n",
    "best_iter_baseline = model_baseline.best_iteration_\n",
    "\n",
    "# Train EFB+GOSS model with tracking\n",
    "print(\"\\nTraining EFB+GOSS model...\")\n",
    "start_time_efb_goss = time.time()\n",
    "model_efb_goss.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result_efb_goss),\n",
    "        lgb.early_stopping(stopping_rounds=10, verbose=True),\n",
    "        tracking_callback(time_per_iter_efb_goss, \"EFB+GOSS Model\")\n",
    "    ]\n",
    ")\n",
    "training_time_efb_goss = time.time() - start_time_efb_goss\n",
    "best_iter_efb_goss = model_efb_goss.best_iteration_\n",
    "\n",
    "# Convert time tracking into actual iteration-based timings\n",
    "time_points_baseline = [t - time_per_iter_baseline[0] for t in time_per_iter_baseline]\n",
    "time_points_efb_goss = [t - time_per_iter_efb_goss[0] for t in time_per_iter_efb_goss]\n",
    "\n",
    "# Extract AUC values only up to the best iteration\n",
    "auc_baseline = evals_result_baseline['valid_0']['auc'][:best_iter_baseline]\n",
    "auc_efb_goss = evals_result_efb_goss['valid_0']['auc'][:best_iter_efb_goss]\n",
    "\n",
    "# Ensure both models have the same iteration count for comparison\n",
    "min_iters = min(best_iter_baseline, best_iter_efb_goss)\n",
    "auc_baseline = auc_baseline[:min_iters]\n",
    "auc_efb_goss = auc_efb_goss[:min_iters]\n",
    "time_points_baseline = time_points_baseline[:min_iters]\n",
    "time_points_efb_goss = time_points_efb_goss[:min_iters]\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nBaseline Model: Best Iteration = {best_iter_baseline}, Training Time = {training_time_baseline:.2f}s\")\n",
    "print(f\"EFB+GOSS Model: Best Iteration = {best_iter_efb_goss}, Training Time = {training_time_efb_goss:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ea1d4-5f55-4da0-933a-ce3911313f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Evaluate final models\n",
    "def evaluate_model(name, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"ROC AUC: {auc:.4f}\")\n",
    "    print(f\"Training Time: {training_time_baseline if name == 'Baseline' else training_time_efb_goss:.2f}s\")\n",
    "\n",
    "evaluate_model(\"Baseline\", model_baseline)\n",
    "evaluate_model(\"EFB+GOSS\", model_efb_goss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdb7eb-1ce8-47f1-ba2a-a08c785e5680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_points_baseline, auc_baseline, label='lgb_baseline', color='orange')\n",
    "plt.plot(time_points_efb_goss, auc_efb_goss, label='LightGBM', color='blue')\n",
    "plt.xlabel('Training Time (seconds)')\n",
    "plt.ylabel('Test Set AUC')\n",
    "plt.title('AUC Progression During Training')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c013e2-b1f6-4116-9f34-17eb95a763ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# ========== LightGBM Parameters & Models ========== #\n",
    "params_baseline = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'enable_bundle': False,        \n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 1.0,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "params_efb_goss = {\n",
    "    'boosting_type': 'goss',       \n",
    "    'enable_bundle': True,         \n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,  \n",
    "    'subsample': 1.0,\n",
    "    'random_state': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "model_baseline = lgb.LGBMClassifier(**params_baseline)\n",
    "model_efb_goss = lgb.LGBMClassifier(**params_efb_goss)\n",
    "\n",
    "# ========== XGBoost Parameters & Models ========== #\n",
    "params_xgb_hist = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'tree_method': 'hist',       # Histogram-based method\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 1.0,\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'auc'\n",
    "}\n",
    "\n",
    "params_xgb_exact = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'tree_method': 'exact',      # Exact greedy method\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'subsample': 1.0,\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'auc'\n",
    "}\n",
    "\n",
    "model_xgb_hist = xgb.XGBClassifier(**params_xgb_hist)\n",
    "model_xgb_exact = xgb.XGBClassifier(**params_xgb_exact)\n",
    "\n",
    "# ========== Tracking Callbacks ========== #\n",
    "# LightGBM Callback\n",
    "def tracking_callback(time_list, model_name):\n",
    "    def callback(env):\n",
    "        current_iter = env.iteration\n",
    "        time_list.append(time.time())\n",
    "        print(f\"{model_name}: Iteration {current_iter}/{env.end_iteration}\", end='\\r', flush=True)\n",
    "    return callback\n",
    "\n",
    "# XGBoost Callback (Custom Implementation)\n",
    "class XGBTimeCallback(xgb.callback.TrainingCallback):\n",
    "    def __init__(self, time_list, model_name):\n",
    "        self.time_list = time_list\n",
    "        self.model_name = model_name\n",
    "        self.start_time = None\n",
    "\n",
    "    def before_training(self, model):\n",
    "        self.start_time = time.time()\n",
    "        return model\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        current_time = time.time() - self.start_time\n",
    "        self.time_list.append(current_time)\n",
    "        print(f\"{self.model_name}: Iteration {epoch}\", end='\\r', flush=True)\n",
    "        return False  # Do not stop training\n",
    "\n",
    "# ========== Train Models & Track Results ========== #\n",
    "# Dictionary to store results for all models\n",
    "evals_result = {\n",
    "    'baseline': {}, \n",
    "    'efb_goss': {},\n",
    "    'xgb_hist': {},\n",
    "    'xgb_exact': {}\n",
    "}\n",
    "\n",
    "time_tracking = {\n",
    "    'baseline': [],\n",
    "    'efb_goss': [],\n",
    "    'xgb_hist': [],\n",
    "    'xgb_exact': []\n",
    "}\n",
    "\n",
    "# Train LightGBM Baseline\n",
    "print(\"Training LightGBM Baseline...\")\n",
    "start_time = time.time()\n",
    "model_baseline.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result['baseline']),\n",
    "        lgb.early_stopping(stopping_rounds=10),\n",
    "        tracking_callback(time_tracking['baseline'], \"Baseline\")\n",
    "    ]\n",
    ")\n",
    "training_time_baseline = time.time() - start_time\n",
    "best_iter_baseline = model_baseline.best_iteration_\n",
    "\n",
    "# Train LightGBM EFB+GOSS\n",
    "print(\"\\nTraining LightGBM EFB+GOSS...\")\n",
    "start_time = time.time()\n",
    "model_efb_goss.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[\n",
    "        lgb.record_evaluation(evals_result['efb_goss']),\n",
    "        lgb.early_stopping(stopping_rounds=10),\n",
    "        tracking_callback(time_tracking['efb_goss'], \"EFB+GOSS\")\n",
    "    ]\n",
    ")\n",
    "training_time_efb_goss = time.time() - start_time\n",
    "best_iter_efb_goss = model_efb_goss.best_iteration_\n",
    "\n",
    "# Train XGBoost Histogram\n",
    "print(\"\\nTraining XGBoost Histogram...\")\n",
    "start_time = time.time()\n",
    "model_xgb_hist.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=False,\n",
    "    callbacks=[XGBTimeCallback(time_tracking['xgb_hist'], \"XGB Hist\")],\n",
    "    evals_result=evals_result['xgb_hist']\n",
    ")\n",
    "training_time_xgb_hist = time.time() - start_time\n",
    "best_iter_xgb_hist = model_xgb_hist.best_iteration\n",
    "\n",
    "# Train XGBoost Exact\n",
    "print(\"\\nTraining XGBoost Exact...\")\n",
    "start_time = time.time()\n",
    "model_xgb_exact.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=False,\n",
    "    callbacks=[XGBTimeCallback(time_tracking['xgb_exact'], \"XGB Exact\")],\n",
    "    evals_result=evals_result['xgb_exact']\n",
    ")\n",
    "training_time_xgb_exact = time.time() - start_time\n",
    "best_iter_xgb_exact = model_xgb_exact.best_iteration\n",
    "\n",
    "# ========== Process Results ========== #\n",
    "# Extract AUC values (LightGBM uses 'valid_0', XGBoost uses 'validation_0')\n",
    "auc_baseline = evals_result['baseline']['valid_0']['auc'][:best_iter_baseline]\n",
    "auc_efb_goss = evals_result['efb_goss']['valid_0']['auc'][:best_iter_efb_goss]\n",
    "auc_xgb_hist = evals_result['xgb_hist']['validation_0']['auc'][:best_iter_xgb_hist]\n",
    "auc_xgb_exact = evals_result['xgb_exact']['validation_0']['auc'][:best_iter_xgb_exact]\n",
    "\n",
    "# Convert time tracking to cumulative seconds\n",
    "time_points = {\n",
    "    'baseline': [t - time_tracking['baseline'][0] for t in time_tracking['baseline']],\n",
    "    'efb_goss': [t - time_tracking['efb_goss'][0] for t in time_tracking['efb_goss']],\n",
    "    'xgb_hist': time_tracking['xgb_hist'],  # Already cumulative\n",
    "    'xgb_exact': time_tracking['xgb_exact']\n",
    "}\n",
    "\n",
    "# ========== Print Results ========== #\n",
    "print(f\"\\nLightGBM Baseline: Best Iter={best_iter_baseline}, Time={training_time_baseline:.2f}s\")\n",
    "print(f\"LightGBM EFB+GOSS: Best Iter={best_iter_efb_goss}, Time={training_time_efb_goss:.2f}s\")\n",
    "print(f\"XGBoost Histogram: Best Iter={best_iter_xgb_hist}, Time={training_time_xgb_hist:.2f}s\")\n",
    "print(f\"XGBoost Exact:     Best Iter={best_iter_xgb_exact}, Time={training_time_xgb_exact:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd944d7a-66a6-4f84-88d4-28cebd8ccea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IR Project)",
   "language": "python",
   "name": "venv_ir_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
